{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import Random\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import figure\n",
    "from math import sqrt\n",
    "from time import monotonic #time and increasing\n",
    "SEED = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gen_rand_pts(N=1000):\n",
    "    \"\"\"\n",
    "    returns 2 lists where the first one contains the x-coordinates of the points generated randomly,\n",
    "    and the second one contains the y-coordinates of the points generated randomly\n",
    "    :param N: (int, optional) default = 1000,\n",
    "        number of random generated points\n",
    "    :return: tuple of 2 lists\n",
    "    \"\"\"\n",
    "    if N<=0:\n",
    "        raise ValueError(\"Wrong value for N\")\n",
    "    rand_gen = Random(x=SEED)\n",
    "    return (\n",
    "        [rand_gen.uniform(a=0, b=1) for _ in range(N)],\n",
    "        [rand_gen.uniform(a=0, b=1) for _ in range(N)]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def loss( x_p, y_p, batch_x, batch_y):\n",
    "    \"\"\"\n",
    "takes the data set and the initial guess and returns the evaluation of our loss function\n",
    ":param data_x:(list of floats) : x-coordinate of the data point for the training data\n",
    ":param data_y:(list of floats) : y-coordinate of the data point for the training data\n",
    ":param x_p:(float) : x-coordinate of the data point for the initial guess\n",
    ":param y_p:(float) : y-coordinate of the data point for the initial guess\n",
    ":return: loss (float): The root mean squared distance between\n",
    "    the point (x_p, y_p) and the data points\n",
    "\"\"\"\n",
    "    n_inv = 1/len(batch_x)\n",
    "    return n_inv * sum(\n",
    "        [ ((x_i-x_p)**2 + (y_i-y_p)**2)**0.5 for x_i, y_i in zip(batch_x, batch_y)]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cal_grad(x_p, y_p):\n",
    "    sum_x , sum_y = 0, 0\n",
    "    c = -1/len(data_x)\n",
    "    for x_i, y_i in zip(data_x, data_y):\n",
    "        inv_sqrt = ( (x_i-x_p) ** 2 + (y_i-y_p) ** 2 ) ** (-0.5)\n",
    "        sum_x += inv_sqrt*(x_i -x_p)\n",
    "        sum_y += inv_sqrt*(y_i - y_p)\n",
    "    return c*sum_x, c*sum_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_x, data_y = gen_rand_pts()\n",
    "x_p, y_p = 0.3, 0.3\n",
    "grad_x, grad_y = cal_grad(x_p, y_p)\n",
    "cur_loss = loss(x_p, y_p, data_x, data_y)\n",
    "print(f\"closed form: gradient for x_p {grad_x}, gradient for y_p {grad_y} \")\n",
    "print(f\"closed form loss = {cur_loss}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pytorch as an example of Autograd engines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "pnt = torch.tensor([0.3, 0.3])\n",
    "pnt.requires_grad = True\n",
    "pnt.retain_grad()#In PyTorch, the retain_grad() method is used to retain the gradients of a tensor, which means that the gradients will not be automatically cleared during the backward pass. This method is useful when you want to compute multiple gradients for a tensor or when you want to access the gradients of an intermediate computation.\n",
    "data = torch.tensor([data_x, data_y])\n",
    "data = data.t()\n",
    "print(data.shape, pnt.shape)\n",
    "\n",
    "loss_torch = torch.mean(torch.sqrt(((data - pnt)**2).sum(dim = 1)))\n",
    "print(f\"loss : {loss_torch}\")\n",
    "loss_torch.backward()\n",
    "print(f\"torch gradient : {pnt.grad.data}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building Autograd from scratch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class comp_node:\n",
    "    \"\"\"\n",
    "A computational node that represents a mathematical operation.\n",
    "\n",
    "Attributes:\n",
    "-----------\n",
    "val : float\n",
    "    The numerical value of the computational node.\n",
    "children : list, optional\n",
    "    A list of child nodes. Default is an empty list.\n",
    "grad : float\n",
    "    The gradient of the computational node with respect to a target variable.\n",
    "op : str\n",
    "    The type of operation performed by the node.\n",
    "backward : function\n",
    "    The function to compute the gradients of this node.\n",
    "\n",
    "Methods:\n",
    "--------\n",
    "__init__(self, val, children=[], op=\"assign\"):\n",
    "    Initializes a computational node object.\n",
    "\n",
    "__to_comp_node(self, obj):\n",
    "    Converts a non-comp_node object to a comp_node object.\n",
    "\n",
    "__sub__(self, other):\n",
    "    Subtracts another computational node from this node.\n",
    "\n",
    "__rsub__(self, other):\n",
    "    Subtracts this node from another computational node.\n",
    "\n",
    "__pow__(self, exponent):\n",
    "    Raises this node to a power.\n",
    "\n",
    "__eq__(self, other):\n",
    "    Checks if this node is equal to another node.\n",
    "\n",
    "__add__(self, other):\n",
    "    Adds another computational node to this node.\n",
    "\n",
    "__radd__(self, other):\n",
    "    Adds this node to another computational node.\n",
    "\n",
    "__mul__(self, other):\n",
    "    Multiplies this node by another computational node.\n",
    "\n",
    "__rmul__(self, other):\n",
    "    Multiplies another computational node by this node.\n",
    "\n",
    "__repr__(self):\n",
    "    Returns a string representation of the computational node.\n",
    "\"\"\"\n",
    "    def __init__(self, val, children=[], op=\"assign\"):\n",
    "        \"\"\"\n",
    "        Initializes a computational node object.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        val : float\n",
    "            The numerical value of the computational node.\n",
    "        children : list, optional\n",
    "             A list of child nodes. Default is an empty list.\n",
    "        op : str, optional\n",
    "            The type of operation performed by the node. Default is \"assign\".\n",
    "        \"\"\"\n",
    "        self.val = val\n",
    "        self.children = children\n",
    "        self.grad = 0\n",
    "        self.op = op\n",
    "        self.backward = lambda : None\n",
    "\n",
    "    def __to_comp_node(self, obj):\n",
    "        \"\"\"\n",
    "        Converts a non-comp_node object to a comp_node object.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        obj : any\n",
    "            The object to be converted.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        comp_node\n",
    "            The converted object as a computational node.\n",
    "        \"\"\"\n",
    "        if not isinstance(obj, comp_node):\n",
    "            return comp_node(val = obj)\n",
    "        return obj\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        \"\"\"\n",
    "    Subtracts another computational node from this node.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    other : comp_node or float\n",
    "        The node or value to be subtracted.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    comp_node\n",
    "        A new computational node representing the subtraction operation.\n",
    "    \"\"\"\n",
    "        \"\"\"This defines the behavior of the - operator for comp_node objects, which represents subtraction. It creates a new comp_node object (out) with the appropriate values and sets its backward propagation function (_backward_prop) to compute the gradients of the current node and its dependency (other) with respect to the output node (out). It then returns the out node.\"\"\"\n",
    "        other = self.__to_comp_node(other)\n",
    "        out = comp_node(val=self.val-other.val, children=[self, other],\n",
    "                        op = \"sub\")\n",
    "        #return self.val - other.val\n",
    "        def _backward_prop():\n",
    "            \"\"\"The += operator is used to accumulate gradients during backpropagation.\n",
    "            In automatic differentiation (autodiff), the gradients are computed using the chain rule of differentiation. Each node in a computation graph (represented by comp_node in this code) stores its gradient with respect to the output of the overall computation. During backpropagation, the gradient of the loss with respect to each intermediate node in the graph is computed and added to the node's gradient.\"\"\"\n",
    "            self.grad += out.grad * 1\n",
    "            other.grad += out.grad * (-1)\n",
    "        out.backward = _backward_prop\n",
    "        return out\n",
    "    def __rsub__(self, other):\n",
    "        \"\"\"This defines the behavior of the - operator when the comp_node object is on the right-hand side of the operator. It simply calls the regular subtraction method with the order of the operands reversed.\"\"\"\n",
    "        other = self.__to_comp_node(other)\n",
    "        return other - self\n",
    "\n",
    "    def __pow__(self, exponent):\n",
    "        \"\"\"This defines the behavior of the ** operator for comp_node objects, which represents exponentiation. It creates a new comp_node object (out) with the appropriate values and sets its backward propagation function (_backward_prop) to compute the gradient of the current node with respect to its dependency (self) and the output node (out). It then returns the out node.\"\"\"\n",
    "        if not isinstance(exponent, (int, float)):\n",
    "            raise ValueError(\" Unsupported Type\")\n",
    "        out = comp_node(val = self.val**exponent, children=[self],\n",
    "                        op=f\"power {exponent}\")\n",
    "\n",
    "        def _backward_prop():\n",
    "            self.grad += out.grad * (exponent * self.val**(exponent - 1))\n",
    "        out.backward = _backward_prop # use no parentheses\n",
    "        return out\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"This defines the behavior of the == operator for comp_node objects, which simply checks if the values of the two nodes are equal.\"\"\"\n",
    "        return  self.val == other.val\n",
    "\n",
    "    def __add__(self, other):\n",
    "        other = self.__to_comp_node(other)\n",
    "        out = comp_node(val=self.val+other.val, children=[self, other],\n",
    "                        op = \"add\")\n",
    "        def _backward_prop():\n",
    "            self.grad += out.grad * 1\n",
    "            other.grad += out.grad * 1\n",
    "        out.backward = _backward_prop\n",
    "        return out\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        other = self.__to_comp_node(other)\n",
    "        return other + self\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = self.__to_comp_node(other)\n",
    "        return comp_node(val = self.val * other.val , op = \"mult\",\n",
    "                         children=[self, other])\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        other = self.__to_comp_node(other)\n",
    "        return self * other\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"op : {self.op} | val : {self.val:0.4f} | \" \\\n",
    "               f\"children : {len(self.children)} | gradient : {self.grad}\"\n",
    "\n",
    "assert comp_node(val=5).val == 5 ,\" Assignment failed\"\n",
    "assert (comp_node(val=5) - comp_node(val=3)).val== 2\n",
    "assert (comp_node(val=5) - 3).val == 2\n",
    "assert (3 - comp_node(val=5)).val == -2\n",
    "assert ((comp_node(val= 5))**2).val == 25\n",
    "assert ((comp_node(val= 5))**2) == comp_node(val = 25)\n",
    "\n",
    "assert (comp_node(val=5) + comp_node(val=3)).val== 8\n",
    "assert (comp_node(val=5) + 3).val == 8\n",
    "assert (3 + comp_node(val=5)).val == 8\n",
    "\n",
    "assert (comp_node(val=5) * comp_node(val=3)).val== 15\n",
    "assert (3 * comp_node(val=5)).val == 15"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_x, data_y = gen_rand_pts(1)\n",
    "print(f\"data_x : {data_x}, data_y : {data_y}\")\n",
    "x_p, y_p = comp_node(val = 0.3), comp_node(val=0.3)\n",
    "def loss_graph(x_p, y_p, data_x, data_y):\n",
    "    I_x, I_y = x_p - data_x, y_p - data_y\n",
    "    g_x, g_y = I_x ** 2, I_y ** 2\n",
    "    M = g_x + g_y\n",
    "    L = M ** 0.5\n",
    "    return L , [L, M, g_x, g_y , I_x, I_y, x_p, y_p]\n",
    "l , rev_topo_sort = loss_graph(x_p, y_p, data_x[0], data_y[0])\n",
    "rev_topo_sort[0].grad = 1\n",
    "#print(l)\n",
    "for i, node in enumerate(rev_topo_sort):\n",
    "    node.backward()\n",
    "    print(i, node)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lecture 9"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adjacency Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An adjacency matrix is a square matrix that represents the connections between vertices in a graph. In an adjacency matrix, the rows and columns represent the vertices of the graph, and the entry in row i and column j indicates whether there is an edge from vertex i to vertex j.\n",
    "\n",
    "Typically, an entry of 1 indicates the presence of an edge, and an entry of 0 indicates the absence of an edge. In the case of weighted graphs, the entry can represent the weight of the edge.\n",
    "\n",
    "The adjacency matrix is a useful tool for analyzing graphs, as it allows for efficient computation of graph properties such as degree, clustering coefficient, and shortest paths. It is also used in algorithms for graph traversal and search, such as Dijkstra's algorithm and the Floyd-Warshall algorithm."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Time and space complexity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The time complexity of working with an adjacency matrix depends on the operation being performed. Here are some common time complexities for different operations on an n x n adjacency matrix:\n",
    "\n",
    "Checking if there is an edge between two vertices: O(1)\n",
    "This operation is constant time, as it simply involves looking up a single entry in the matrix.\n",
    "\n",
    "Finding the degree of a vertex: O(n)\n",
    "To find the degree of a vertex, we need to count the number of 1's in the row or column corresponding to that vertex. Since there are n entries in the row or column, this operation takes O(n) time.\n",
    "\n",
    "Computing the transitive closure of the graph: O(n^3)\n",
    "The transitive closure of a graph is a matrix that indicates whether there is a path between every pair of vertices. It can be computed using the Floyd-Warshall algorithm, which has a time complexity of O(n^3).\n",
    "\n",
    "Determining if the graph is connected: O(n^2)\n",
    "To determine if the graph is connected, we can perform a depth-first or breadth-first search from any vertex and check if all vertices are reachable. This operation requires visiting each vertex once, which takes O(n) time, and checking if there is an edge between two vertices, which takes O(1) time. Therefore, the total time complexity is O(n^2).\n",
    "\n",
    "Finding the shortest path between two vertices: O(n^3)\n",
    "The shortest path between two vertices can be computed using the Floyd-Warshall algorithm, which has a time complexity of O(n^3).\n",
    "\n",
    "In general, working with an adjacency matrix takes O(n^2) space, as each entry in the matrix needs to be stored. The time complexity of other operations will depend on the specific algorithm being used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The problem with adjacency matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While adjacency matrices are a useful tool for analyzing graphs, there are some potential problems associated with their use:\n",
    "\n",
    "Space complexity: The space required for an adjacency matrix grows quadratically with the number of vertices in the graph. For large graphs, this can become a significant memory burden, especially if the graph is sparse (i.e., has few edges).\n",
    "\n",
    "Limited scalability: Adjacency matrices can become computationally expensive to work with for very large graphs. Many graph algorithms have time complexity that grows polynomially or worse with the number of vertices or edges, which can make them impractical to use for graphs with millions or billions of vertices.\n",
    "\n",
    "Inefficient for sparse graphs: If the graph is sparse (i.e., has few edges), then the majority of the entries in the adjacency matrix will be 0. This means that a lot of space is wasted storing information that is not necessary for analyzing the graph.\n",
    "\n",
    "Updating the graph: If the graph is dynamic and edges are added or removed frequently, then updating the adjacency matrix can be computationally expensive. Adding or removing an edge requires updating several entries in the matrix, which can take O(n^2) time.\n",
    "\n",
    "In contrast, adjacency lists can address some of these issues, as they use less memory and can be more efficient for sparse graphs or dynamic graphs. However, they can be less efficient for some graph algorithms, such as computing the transitive closure of the graph, which is more efficiently computed using an adjacency matrix."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Implementing adjacency matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def adjacency_matrix(edges, num_vertices):\n",
    "    \"\"\"\n",
    "    Takes in a list of edges and the number of vertices in the graph and returns an adjacency matrix as a 2D array.\n",
    "\n",
    "    Parameters:\n",
    "    - edges: a list of tuples representing edges in the graph, where each tuple contains two vertices (strings or integers)\n",
    "    - num_vertices: an integer representing the number of vertices in the graph\n",
    "\n",
    "    Returns:\n",
    "    - a 2D array representing the adjacency matrix of the graph\n",
    "    \"\"\"\n",
    "    adj_matrix = [[0 for _ in range(num_vertices)] for _ in range(num_vertices)]\n",
    "    for edge in edges:\n",
    "        v1, v2 = edge\n",
    "        adj_matrix[v1][v2] = 1\n",
    "        adj_matrix[v2][v1] = 1\n",
    "    return adj_matrix\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adjacency lists"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An adjacency list is a way to represent a graph as a collection of linked lists, where each linked list corresponds to a vertex in the graph and contains the vertices that are adjacent to it.\n",
    "\n",
    "In an adjacency list, each vertex in the graph is represented as a key in a dictionary, and the value associated with each key is a list of the vertices adjacent to that vertex. For an undirected graph, each edge should be added to the adjacency list of both vertices connected by the edge.\n",
    "\n",
    "For example, consider the following undirected graph:\n",
    "A -- B\n",
    "|    |\n",
    "C -- D\n",
    "This graph can be represented using the following adjacency list:\n",
    "{\n",
    "  \"A\": [\"B\", \"C\"],\n",
    "  \"B\": [\"A\", \"D\"],\n",
    "  \"C\": [\"A\", \"D\"],\n",
    "  \"D\": [\"B\", \"C\"]\n",
    "}\n",
    "In this adjacency list, the key \"A\" has a value of [\"B\", \"C\"], indicating that vertex \"A\" is adjacent to vertices \"B\" and \"C\". Similarly, the key \"B\" has a value of [\"A\", \"D\"], indicating that vertex \"B\" is adjacent to vertices \"A\" and \"D\".\n",
    "\n",
    "Note that since the graph is undirected, each edge appears in the adjacency list of both vertices it connects.\n",
    "\n",
    "Using an adjacency list can be useful for certain algorithms that require traversing the neighbors of each vertex in the graph. It is also more memory-efficient than an adjacency matrix for sparse graphs, where the number of edges is much smaller than the number of possible edges."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 7.0.4 (20221203.1631)\n -->\n<!-- Pages: 1 -->\n<svg width=\"218pt\" height=\"260pt\"\n viewBox=\"0.00 0.00 218.00 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 214,-256 214,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"55\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"55\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M33.64,-216.41C36.77,-208.57 40.6,-198.99 44.15,-190.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"47.39,-191.46 47.85,-180.88 40.89,-188.86 47.39,-191.46\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"38\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"38\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\n</g>\n<!-- 0&#45;&gt;3 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M23.75,-215.89C21.95,-205.54 19.91,-192.06 19,-180 15.49,-133.21 24.61,-79.09 31.4,-47.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"34.79,-47.87 33.53,-37.35 27.96,-46.37 34.79,-47.87\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"93\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"93\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\n</g>\n<!-- 1&#45;&gt;4 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M63.81,-144.76C68.27,-136.55 73.8,-126.37 78.84,-117.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"81.82,-118.94 83.51,-108.48 75.67,-115.6 81.82,-118.94\"/>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"146\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"146\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M134.24,-145.46C127.58,-136.67 119.11,-125.48 111.57,-115.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"114.47,-113.56 105.64,-107.7 108.89,-117.78 114.47,-113.56\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"165\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"165\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5</text>\n</g>\n<!-- 2&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>2&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M150.6,-144.05C152.65,-136.49 155.13,-127.37 157.44,-118.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"160.8,-119.82 160.05,-109.25 154.05,-117.98 160.8,-119.82\"/>\n</g>\n<!-- 3&#45;&gt;1 -->\n<g id=\"edge6\" class=\"edge\">\n<title>3&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M40.05,-36.11C42.9,-59.92 48.1,-103.37 51.55,-132.22\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"48.07,-132.57 52.74,-142.09 55.02,-131.74 48.07,-132.57\"/>\n</g>\n<!-- 4&#45;&gt;3 -->\n<g id=\"edge7\" class=\"edge\">\n<title>4&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M80.79,-73.46C73.89,-64.67 65.09,-53.48 57.27,-43.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"60.04,-41.38 51.11,-35.68 54.53,-45.71 60.04,-41.38\"/>\n</g>\n<!-- 5&#45;&gt;5 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M184.9,-102.43C197.69,-105.68 210,-101.53 210,-90 210,-81.98 204.05,-77.54 196.12,-76.66\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"196.09,-73.15 186.4,-77.45 196.65,-80.13 196.09,-73.15\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.graphs.Digraph at 0x284039ab1c0>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_1_vertices = set(range(8))\n",
    "graph_1_edges = {\n",
    "    0 : [1, 4],\n",
    "    1 : [0, 5],\n",
    "    2 : [5, 6],\n",
    "    3 : [7],\n",
    "    4 : [0],\n",
    "    5 : [2, 6],\n",
    "    6 : [2, 5, 7],\n",
    "    7 : [3,6],\n",
    "}\n",
    "\n",
    "graph_2_vertices = set(range(6))\n",
    "graph_2_edges = {\n",
    "    0 : [1, 3],\n",
    "    1 : [4],\n",
    "    2 : [4, 5],\n",
    "    3 : [1],\n",
    "    4 : [3],\n",
    "    5 : [5],\n",
    "}\n",
    "\n",
    "from graphviz import Digraph, Graph\n",
    "\n",
    "def draw(vertices:set, edges:dict, directed:bool):\n",
    "    \"\"\"\n",
    "    Takes in a set of vertices and a dictionary of edges and uses Graphviz to draw a visualization of the graph.\n",
    "\n",
    "    Parameters:\n",
    "    - vertices: a set of vertices in the graph\n",
    "    - edges: a dictionary of edges in the graph, where each key is a vertex and the value is a list of adjacent vertices\n",
    "\n",
    "    Returns:\n",
    "    - a Graphviz Digraph object representing the visualization of the graph\n",
    "    \"\"\"\n",
    "    global already_drawn\n",
    "    if directed :\n",
    "        dot = Digraph(format=\"svg\")  # creates a new Digraph object with the SVG format\n",
    "    else:\n",
    "        dot = Graph(format='svg')\n",
    "    for v in vertices:\n",
    "        dot.node(name=str(v), label=f\"{v}\")  # adds a node to the graph for each vertex, with its label equal to its value\n",
    "    if not directed:\n",
    "        already_drawn = set()\n",
    "    for k, v in edges.items():\n",
    "        for curr_v in v:\n",
    "            if directed:\n",
    "                dot.edge(str(k), str(curr_v))  # adds an edge between each vertex and its adjacent vertices\n",
    "            else:\n",
    "                sorted_edge = tuple(sorted([k, curr_v]))\n",
    "                if sorted_edge not in already_drawn:\n",
    "                    already_drawn.add(sorted_edge)\n",
    "                    dot.edge(str(k), str(curr_v))\n",
    "    return dot  # returns the completed graph\n",
    "\n",
    "\n",
    "graph_1 = draw(graph_2_vertices, graph_2_edges, True)\n",
    "graph_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Graph Traversal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "given a Graph G and a vertex to start at  S"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BFS\n",
    "\n",
    "BFS stands for Breadth-First Search. It is a graph traversal algorithm that starts at a given source vertex and explores all the vertices at the same level (i.e., the same distance from the source) before moving on to the next level. The algorithm explores the graph in a breadth-first manner, hence the name.\n",
    "\n",
    "Here's a step-by-step algorithm to perform BFS on a graph:\n",
    "\n",
    "Initialize a queue and a set of visited vertices.\n",
    "Add the source vertex to the queue and mark it as visited.\n",
    "While the queue is not empty, dequeue the next vertex from the queue.\n",
    "For each unvisited neighbor of the dequeued vertex, mark it as visited and enqueue it.\n",
    "Repeat steps 3-4 until the queue is empty."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " visiting node : 1\n",
      " visiting node : 4\n",
      " visiting node : 3\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "#setting the graph\n",
    "graph_vertices = graph_2_vertices\n",
    "graph_edges = graph_2_edges\n",
    "\n",
    "#setting the source vertex\n",
    "s = 1\n",
    "\n",
    "#creating q\n",
    "q = deque()\n",
    "visited = set()\n",
    "\n",
    "#initializing\n",
    "q.append(s)\n",
    "visited.add(s)\n",
    "\n",
    "while len(q) > 0:\n",
    "    #pop the queue\n",
    "    curr_vertex = q.popleft()\n",
    "\n",
    "    #visit Nodes\n",
    "    print(f\" visiting node : {curr_vertex}\")\n",
    "\n",
    "\n",
    "    for neighbour  in graph_edges[curr_vertex]:\n",
    "        if neighbour not in visited:\n",
    "            q.append(neighbour)\n",
    "            visited.add(neighbour)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DFS\n",
    "DFS stands for Depth-First Search. It is a graph traversal algorithm that starts at a given source vertex and explores as far as possible along each branch before backtracking. The algorithm explores the graph in a depth-first manner, hence the name.\n",
    "\n",
    "Here's a step-by-step algorithm to perform DFS on a graph:\n",
    "\n",
    "Initialize a stack and a set of visited vertices.\n",
    "Add the source vertex to the stack and mark it as visited.\n",
    "While the stack is not empty, pop the next vertex from the stack.\n",
    "For each unvisited neighbor of the popped vertex, mark it as visited and push it onto the stack.\n",
    "Repeat steps 3-4 until the stack is empty."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visit before neighbours : 0\n",
      "visit before neighbours : 1\n",
      "visit before neighbours : 4\n",
      "visit before neighbours : 3\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "visited = set()\n",
    "def dfs(v):\n",
    "    if v in visited:\n",
    "        return\n",
    "    else:\n",
    "        visited.add(v)\n",
    "        print(f\"visit before neighbours : {v}\")\n",
    "        for neighbour in graph_edges[v]:\n",
    "            dfs(neighbour)\n",
    "dfs(s)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new dfs search \n",
      "visit after neighbours : 0\n",
      "visit after neighbours : 1\n",
      "visit after neighbours : 4\n",
      "visit after neighbours : 3\n",
      "new dfs search \n",
      "visit after neighbours : 2\n",
      "visit after neighbours : 5\n"
     ]
    }
   ],
   "source": [
    "visited = set()\n",
    "def dfs(v):\n",
    "    if v in visited:\n",
    "        return\n",
    "    else:\n",
    "        visited.add(v)\n",
    "        print(f\"visit after neighbours : {v}\")\n",
    "    for neighbour in graph_edges[v]:\n",
    "            dfs(neighbour)\n",
    "\n",
    "for node in graph_vertices:\n",
    "    if node not in visited:\n",
    "        print(f\"new dfs search \")\n",
    "        dfs(node)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Topological"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " topological sort visiting 3\n",
      " topological sort visiting 4\n",
      " topological sort visiting 1\n",
      " topological sort visiting 0\n",
      " topological sort visiting 5\n",
      " topological sort visiting 2\n",
      "\n",
      " a valid topological sort is [2, 5, 0, 1, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "visited = set()\n",
    "srt = []\n",
    "def dfs(node):\n",
    "    if node in visited:\n",
    "        return\n",
    "    visited.add(node)\n",
    "    for neighbor in graph_edges[node]:\n",
    "        dfs(neighbor)\n",
    "    print(f\" topological sort visiting {node}\")\n",
    "    srt.append(node)\n",
    "\n",
    "\n",
    "for node in graph_vertices:\n",
    "    if node not in visited:\n",
    "        dfs(node)\n",
    "print(f\"\\n a valid topological sort is {srt[::-1]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
